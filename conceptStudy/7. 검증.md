# 7. 검증

참고문헌 : 
1. 구글 머신러닝 단기 집중과정

[Google의 머신러닝 단기 집중과정](https://developers.google.com/machine-learning/crash-course/ml-intro?hl=ko)

## 학습 세트와 테스트 세트로의 분할에서의 문제점

![7-1](https://github.com/Se-Hun/DeepLearningStudy/blob/master/conceptStudy/png/7-1.PNG)

위의 그림은 학습 세트와 테스트 세트로 데이터 셋을 분할했을때의 워크플로우를 보여준다.

즉, **우리는 학습 세트로 모델을 학습하고 테스트 세트로 평가하여 가장 우수해보이는 모델과 매개변수를 맞추어 그것을 모델로 사용**하기로 했었다.

하지만 이것은 새로운 데이터를 가지고 실제로 예측했을 때, 정확도가 떨어질 수도 있다는 문제점이 있다.

그 이유는 테스트 세트에 너무 과적합되는 경우, 일반화가 안 되어 예측이 잘 되지 않을 수도 있기 때문이다.

## 검증 세트

위의 문제점을 해결하기 위해 우리는 다음과 같이 데이터 세트를 나눈다.

![7-2](https://github.com/Se-Hun/DeepLearningStudy/blob/master/conceptStudy/png/7-2.PNG)

이렇게 분할하면 다음과 같은 워크플로우를 가진다.

![7-3](https://github.com/Se-Hun/DeepLearningStudy/blob/master/conceptStudy/png/7-3.PNG)

즉, **학습 세트를 평가하기 위해 검증 세트를 사용하고 검증 세트에서 가장 우수한 결과를 보이는 모델과 매개변수를 선택하여 그것을 가지고 테스트 세트로 결과를 확인하는 것이다.**

이 방식은 테스트 세트가 보다 적게 노출되므로 일반화가 더 잘 된다.

## batch와 epoch

**batch_size:** 쪼개진 데이터 묶음의 size를 의미한다.

**epoch:** 전체 데이터를 다 돌렸을 때 한 epoch(세대)가 지나갔다고 한다.

즉, 내가 20,000개의 데이터를 가지고 모델을 만들고자 한다고 생각해보자.

batch_size를 100으로 지정하고 epoch를 2번 지나가게 한다면 한 번의 epoch당 200개의 batch 묶음이 학습되고 그렇게 두 번의 epoch를 지나면 20,000개의 데이터를 두 번 학습시킨 셈이 되기 때문에 40,000개의 데이터가 학습되는 것이다.

## 실습

[validation.ipynb](https://github.com/Se-Hun/DeepLearningStudy/blob/master/conceptStudy/code/validation.ipynb)

colab의 validation.ipynb를 통해 실습해보도록 하자.

다음은 실습의 내용을 요약한 과정이다.

****

첫째, 필요한 라이브러리 추가하기

둘째, 데이터 불러오기

셋째, 입력 특성과 target 특성 나누기

넷째, 훈련셋과 검증셋으로 나누기

다섯째, 데이터 시각화를 통해 조사해보기

여섯째, 입력 함수 정의 => batch, epoch, shuffle

일곱째, 모델 학습 시키기

여덟째, 전체 데이터셋에서 테스트셋 추출

아홉째, 테스트 데이터로 정확도 평가

****